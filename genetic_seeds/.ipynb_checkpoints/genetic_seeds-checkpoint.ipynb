{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 13:13:04.278557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-01 13:13:04.422193: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-01 13:13:04.427626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:\n",
      "2023-03-01 13:13:04.427639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-01 13:13:04.453593: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-01 13:13:05.113653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:\n",
      "2023-03-01 13:13:05.113730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:\n",
      "2023-03-01 13:13:05.113736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V1     V2      V3     V4     V5     V6     V7  Y\n",
       "0    15.26  14.84  0.8710  5.763  3.312  2.221  5.220  1\n",
       "1    14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
       "2    14.29  14.09  0.9050  5.291  3.337  2.699  4.825  1\n",
       "3    13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
       "4    16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1\n",
       "..     ...    ...     ...    ...    ...    ...    ... ..\n",
       "205  12.19  13.20  0.8783  5.137  2.981  3.631  4.870  3\n",
       "206  11.23  12.88  0.8511  5.140  2.795  4.325  5.003  3\n",
       "207  13.20  13.66  0.8883  5.236  3.232  8.315  5.056  3\n",
       "208  11.84  13.21  0.8521  5.175  2.836  3.598  5.044  3\n",
       "209  12.30  13.34  0.8684  5.243  2.974  5.637  5.063  3\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./seeds.csv', sep = ',')\n",
    "print (np.shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "print(y)\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 0 2 0 2 0 2 1 2 2 1 0 1 2 0 2 1 1 0 2 1 1 2 0 1 0 2 2 0 1 0 1 1 2\n",
      " 1 1 2 2 2 2 1 2 0 2 1 1 0 0 2 1 0 0 1 1 0 0 0 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "ls=np.argmax(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (147, 7)\n",
      "Shape of X_test:  (63, 7)\n",
      "Shape of y_train:  (147, 3)\n",
      "Shape of y_test (63, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",Y_train.shape)\n",
    "print(\"Shape of y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# clf = MLPClassifier(beta_1=0.004044058262057914, beta_2=0.2692099545241596,\n",
    "#               epsilon=0.4100816459563625, hidden_layer_sizes=3, max_iter=150,\n",
    "#               momentum=0.8221177331942455, nesterovs_momentum=False,\n",
    "#               solver='lbfgs', validation_fraction=0.511318982546456,alpha=0.0001).fit(X_train, Y_train)\n",
    "# clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = load('./Seeds.MLP_clf.joblib')\n",
    "#clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=clf.coefs_[0]\n",
    "b1=clf.intercepts_[0]\n",
    "w2=clf.coefs_[1]\n",
    "b2=clf.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5.42241408, -9.66055707,  2.42630048],\n",
       "        [-1.22839798, -4.69464478,  5.58771364],\n",
       "        [ 0.66819578,  0.14264775, -0.47650837]]),\n",
       " array([  0.20485787,  18.82540503, -18.76383221])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  3.09378954, -14.60169155,  -0.43685888],\n",
       "        [ -3.87836867,  -5.99351853,  -0.52980951],\n",
       "        [  6.02173394,  -3.97068298,  -0.37464544],\n",
       "        [ 21.81603511,  -3.65623394,  -0.24820606],\n",
       "        [-15.95452434,  14.24188188,  -0.08347388],\n",
       "        [ -8.75904303,  -0.73741035,   0.18497675],\n",
       "        [-21.55587593,   4.51104486,  -0.45332955]]),\n",
       " array([ 9.57167129,  7.36444659, -0.35963171])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(beta_1=0.004044058262057914, beta_2=0.2692099545241596,\n",
       "              epsilon=0.4100816459563625, hidden_layer_sizes=3, max_iter=150,\n",
       "              momentum=0.8221177331942455, nesterovs_momentum=False,\n",
       "              solver=&#x27;lbfgs&#x27;, validation_fraction=0.511318982546456)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(beta_1=0.004044058262057914, beta_2=0.2692099545241596,\n",
       "              epsilon=0.4100816459563625, hidden_layer_sizes=3, max_iter=150,\n",
       "              momentum=0.8221177331942455, nesterovs_momentum=False,\n",
       "              solver=&#x27;lbfgs&#x27;, validation_fraction=0.511318982546456)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(beta_1=0.004044058262057914, beta_2=0.2692099545241596,\n",
       "              epsilon=0.4100816459563625, hidden_layer_sizes=3, max_iter=150,\n",
       "              momentum=0.8221177331942455, nesterovs_momentum=False,\n",
       "              solver='lbfgs', validation_fraction=0.511318982546456)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genetic algorithm to determine the relu size, weight size, bias size and sparsity\n",
    "x1: relu_size\n",
    "x2: weight_size\n",
    "x3: bias_size\n",
    "x4: sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem: max( blackbox(x1,x2,x3,x4)\n",
    "         min ( x1*x2*x3)\n",
    "       s.t\n",
    "         2 < x1,x2,x3 < 8\n",
    "         x4 belongs to [0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/hls4ml/converters/__init__.py:16: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import hls4ml\n",
    "import write_mlp_mergemult_ps as wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paretos_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    paretos = pickle.load(fp)\n",
    "with open(\"costs_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    costs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "identity=0\n",
    "for sol in paretos:\n",
    "    \n",
    "    import weightsharing as ws\n",
    "    from importlib import reload\n",
    "    \n",
    "    sparsity_val = float(sol[5]/10)\n",
    "    relusize_f = int(sol[0])\n",
    "    weight_size_f1 = int(sol[1])\n",
    "    bias_size_f1 = int(sol[2])\n",
    "    weight_size_f2 = int(sol[3])\n",
    "    bias_size_f2 = int(sol[4])\n",
    "    input_s = int(sol[6])\n",
    "    int_relu = int(sol[7])\n",
    "    int_w1=1\n",
    "    int_b1=0\n",
    "    int_w2=1\n",
    "    int_b2=0\n",
    "    input_size = int(input_s)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    layer1=7\n",
    "    layer2=3\n",
    "    layer3=3\n",
    "    i=99\n",
    "    epochs=15\n",
    "    lr=0.001\n",
    "    X = df.drop('Y', axis = 1).values\n",
    "    y = df.Y\n",
    "    le = LabelEncoder()\n",
    "    print(y)\n",
    "    y = le.fit_transform(y)\n",
    "    print(le.classes_)\n",
    "    y = to_categorical(y, 3)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "    print(X_train.shape)\n",
    "    # reload(pv)\n",
    "    # model=pv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,sparsity,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "    norm = 2**input_s\n",
    "    sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i] = [int(x*norm)/norm for x in X_train[i]]\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i] = [int(x*norm)/norm for x in X_test[i]]\n",
    "\n",
    "\n",
    "    print(\"INPUT IS \" + str(input_s)+ \"NORM IS \" + str(norm)+ \"RELU IS \"+str(relusize_f)+\" INT RELU\" +str(int_relu)+\" WEIGHTS 1 ARE \"+str(weight_size_f1)+\" BIASES 1 ARE \"+str(bias_size_f1)+\" WEIGHTS 2 ARE \"+str(weight_size_f2)+\" BIASES 2 ARE \"+str(bias_size_f2)+\" SPARSITY : \"+str(sparsity_val))\n",
    "\n",
    "    weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "    relu_size=(relusize_f,int_relu)\n",
    "\n",
    "    model.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(layer3, name='output',\n",
    "                    kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "    pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=300, frequency=100)}\n",
    "    model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    model.layers[0].set_weights(wb1)\n",
    "    model.layers[2].set_weights(wb2)\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks= all_callbacks( outputDir = 'seeds_classification_prune')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(X_train, Y_train, batch_size=1,\n",
    "                epochs=15,validation_split=0.2, verbose=0, shuffle=True,\n",
    "                callbacks = callbacks.callbacks);\n",
    "    model = strip_pruning(model)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "    accuracy=model.evaluate(X_test,Y_test)\n",
    "    print(model.get_weights())\n",
    "    print(\" ACCURACY IS \"+str(accuracy[1]) )\n",
    "\n",
    "    weights=model.trainable_variables\n",
    "    weights1=model.trainable_variables\n",
    "\n",
    "    #-- do sharing ---\n",
    "    int_relu = sol[7]+1\n",
    "    int_w1=1\n",
    "    int_b1=1\n",
    "    int_w2=1\n",
    "    int_b2=1\n",
    "\n",
    "    reload(ws)\n",
    "    results, solutions, nodes, weightsall = ws.top_genetic(weights1,15, weight_size_f1, int_w1, weight_size_f2, int_w2, bias_size_f1, int_b1, bias_size_f2, int_b2,input_size, relusize_f, int_relu, X_test, Y_test, X_train, Y_train)\n",
    "\n",
    "    # -- create the verilogs ---\n",
    "    import write_mlp_mergemult_ps as wv1\n",
    "    for i in range(0,len(results)):\n",
    "        weight_bias_size=[ [ (weight_size_f1,int_w1), (bias_size_f1,int_b1) ], [ (weight_size_f2,int_w2), (bias_size_f2,int_b2) ] ]\n",
    "        relu_size=(relusize_f,int_relu-1)\n",
    "        model.set_weights(weightsall[i])\n",
    "    \n",
    "        #4)Create the verilog\n",
    "        def aptype_to_size(ap):\n",
    "            if \"ap_int\" in ap:\n",
    "                s=ap.split('<')[1].split('>')[0]\n",
    "                i=s\n",
    "            else:\n",
    "                s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "            return (int(s),int(i))\n",
    "\n",
    "        #scale weights\n",
    "        allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "        #cast weights to integer & transpose\n",
    "        allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "        weight_list=allweightsT[0::2]\n",
    "        bias_list=allweightsT[1::2]\n",
    "        #set params\n",
    "        config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "        last_layer=\"linear\"\n",
    "        input_size = (input_s,0)\n",
    "        relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "        weight_bias_size= [\n",
    "            [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "            [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "        ]\n",
    "        sum_relu_size=[\n",
    "            [(16,6),relu_size],\n",
    "            [(16,6),(32,6)]\n",
    "        ]\n",
    "        filename = \"Shared_pareto\"+str(identity)+\"_iter\"+str(i)+\"_info_\"+str(relusize_f)+str(weight_size_f1)+str(bias_size_f1)+str(weight_size_f2)+str(bias_size_f2)+str(input_s)+ str(int_relu)+\"-\"+str(accuracy[1])\n",
    "        x = os.path.join(\"./shared\", filename)\n",
    "        f=open(x,\"w\")\n",
    "        \n",
    "        #x = os.path.join(\"./paretos\", filename)\n",
    "\n",
    "        wv1.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "        f.close()\n",
    "\n",
    "        #f=open(\"sim.Xtest\"+filename,\"w\")\n",
    "        #np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "        f.close()\n",
    "\n",
    "        dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "\n",
    "        print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "    print(\"THAT WAS PARETO SOLUTION\"+str(identity))\n",
    "    identity += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weightsharing as ws\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1=model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.93\n",
    "sparsity_val = 0\n",
    "relusize_f = 7\n",
    "weight_size_f1 = 4\n",
    "bias_size_f1 = 2\n",
    "weight_size_f2 = 3\n",
    "bias_size_f2 = 3\n",
    "input_size = 4\n",
    "int_relu = 1\n",
    "int_w1=1\n",
    "int_b1=1\n",
    "int_w2=1\n",
    "int_b2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.92\n",
    "sparsity_val = 0\n",
    "relusize_f = 4\n",
    "weight_size_f1 = 5\n",
    "bias_size_f1 = 3\n",
    "weight_size_f2 = 3\n",
    "bias_size_f2 = 2\n",
    "input_size = 4\n",
    "int_relu = 1\n",
    "int_w1=1\n",
    "int_b1=1\n",
    "int_w2=1\n",
    "int_b2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1=weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results, solutions, nodes, weightsall = ws.top_genetic(weights1,15, weight_size_f1, int_w1, weight_size_f2, int_w2, bias_size_f1, int_b1, bias_size_f2, int_b2,input_size, relusize_f, int_relu, X_test, Y_test, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import write_mlp_mergemult_ps as wv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import write_mlp_mergemult_ps as wv1\n",
    "for i in range(0,len(results)):\n",
    "    weight_bias_size=[ [ (weight_size_f1,int_w1), (bias_size_f1,int_b1) ], [ (weight_size_f2,int_w2), (bias_size_f2,int_b2) ] ]\n",
    "    relu_size=(relusize_f,int_relu-1)\n",
    "    model.set_weights(weightsall[i])\n",
    "    identity=i\n",
    "    #4)Create the verilog\n",
    "    def aptype_to_size(ap):\n",
    "        if \"ap_int\" in ap:\n",
    "            s=ap.split('<')[1].split('>')[0]\n",
    "            i=s\n",
    "        else:\n",
    "            s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "        return (int(s),int(i))\n",
    "\n",
    "    #scale weights\n",
    "    allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "    #cast weights to integer & transpose\n",
    "    allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "    weight_list=allweightsT[0::2]\n",
    "    bias_list=allweightsT[1::2]\n",
    "    #set params\n",
    "    config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    last_layer=\"linear\"\n",
    "    input_size = (input_s,0)\n",
    "    relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "    weight_bias_size= [\n",
    "        [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "        [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "    ]\n",
    "    sum_relu_size=[\n",
    "        [(16,6),relu_size],\n",
    "        [(16,6),(32,6)]\n",
    "    ]\n",
    "\n",
    "    filename = \"top_pareto\"+str(3)+str(i)+\".v\"\n",
    "    #x = os.path.join(\"./paretos\", filename)\n",
    "    f=open(filename,\"w\")\n",
    "\n",
    "    wv1.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "    f.close()\n",
    "\n",
    "    f=open(\"sim.Xtest\"+filename,\"w\")\n",
    "    np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "    f.close()\n",
    "\n",
    "    dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "\n",
    "    print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackbox as bb\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.operators.repair.rounding import RoundingRepair\n",
    "import area as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self,weightsbiases1,weightsbiases2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train):\n",
    "        self.weightsbiases1=weightsbiases1\n",
    "        self.weightsbiases2=weightsbiases2\n",
    "        self.layer1=layer1\n",
    "        self.layer2=layer2\n",
    "        self.layer3=layer3\n",
    "        self.X_test=X_test\n",
    "        self.X_train=X_train\n",
    "        self.Y_test=Y_test\n",
    "        self.Y_train=Y_train\n",
    "        #x[0]: relu_size\n",
    "        #x[1]: weight size layer1\n",
    "        #x[2]: bias size layer1\n",
    "        #x[3]: weight size layer2\n",
    "        #x[4]: bias size layer2\n",
    "        #x[5]: pruning sparsity\n",
    "        #x[6]: input size\n",
    "        #x[7]: int relu size\n",
    "        \n",
    "        super().__init__(n_var=8,\n",
    "                         n_obj=2,\n",
    "                         n_ieq_constr=0,\n",
    "                         xl=np.array([3,2,2,2,2,0,2,0]),\n",
    "                         xu=np.array([7,7,5,7,5,8,4,1]),\n",
    "                         vtype=int)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        accuracy, weights = bb.blackbox(self.weightsbiases1,self.weightsbiases2, x[0], x[1], x[2], x[3], x[4], x[5], x[6] , x[7],  self.layer1, self.layer2, self.layer3, self.X_test, self.Y_test, self.X_train, self.Y_train)\n",
    "        f1 = 1- accuracy\n",
    "        f2 = ar.area(weights,x[6],x[0],x[1],x[3],self.layer1,self.layer2,self.layer3)\n",
    "\n",
    "        out[\"F\"] = [f1, f2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=7\n",
    "layer2=3\n",
    "layer3=3\n",
    "problem = MyProblem(wb1,wb2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithm = NSGA2(\n",
    "    pop_size=80,\n",
    "    n_offsprings=60,\n",
    "    sampling=IntegerRandomSampling(),\n",
    "    crossover=SBX(vtype=float, repair=RoundingRepair()),\n",
    "    mutation=PM( vtype=float, repair=RoundingRepair()),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.termination import get_termination\n",
    "\n",
    "termination = get_termination(\"n_gen\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "X = res.X\n",
    "F = res.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-res.F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot all the solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "pop=res.pop\n",
    "vals=pop.get(\"F\")\n",
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(vals, facecolor=\"none\", edgecolor=\"red\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the pareto solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(val, facecolor=\"none\", edgecolor=\"blue\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=7\n",
    "layer_2=3\n",
    "layer_3=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paretos=sols\n",
    "costs=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"paretos_seeds\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(res.X, fp)\n",
    "# with open(\"costs_seeds\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(res.F, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 4, 3, 4, 4, 4, 4, 1],\n",
       "       [4, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [5, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [4, 2, 3, 2, 3, 6, 4, 0],\n",
       "       [5, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [6, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [3, 2, 3, 2, 3, 6, 3, 0],\n",
       "       [3, 2, 3, 2, 5, 3, 4, 1],\n",
       "       [3, 2, 3, 2, 5, 0, 4, 1],\n",
       "       [6, 4, 3, 4, 4, 4, 4, 0],\n",
       "       [5, 2, 3, 2, 3, 6, 4, 1],\n",
       "       [4, 2, 3, 2, 3, 6, 3, 1],\n",
       "       [3, 2, 2, 2, 5, 8, 3, 1],\n",
       "       [6, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [5, 2, 2, 2, 3, 6, 4, 1],\n",
       "       [3, 2, 3, 2, 5, 2, 4, 1],\n",
       "       [7, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [7, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [3, 2, 3, 2, 5, 1, 4, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paretos_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    paretos = pickle.load(fp)\n",
    "with open(\"costs_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    costs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'only_pruning_verilog' from '/home/argykokk/Desktop/TC/genetic_seeds/only_pruning_verilog.py'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pareto_verilogs as pv\n",
    "import pareto_weight_sharing_verilogs as pwsv\n",
    "import pareto_clustering_verilogs as pcv\n",
    "import pareto_only_quantization_verilogs as poqv\n",
    "import only_pruning_verilog as opv\n",
    "from importlib import reload\n",
    "reload(pv)\n",
    "reload(pwsv)\n",
    "reload(pcv)\n",
    "reload(poqv)\n",
    "reload(opv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "layer1=7\n",
    "layer2=3\n",
    "layer3=3\n",
    "epochs=14\n",
    "lr=0.003\n",
    "#opv.generate(i,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 4, 3, 4, 4, 4, 4, 1],\n",
       "       [4, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [5, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [4, 2, 3, 2, 3, 6, 4, 0],\n",
       "       [5, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [6, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [3, 2, 3, 2, 3, 6, 3, 0],\n",
       "       [3, 2, 3, 2, 5, 3, 4, 1],\n",
       "       [3, 2, 3, 2, 5, 0, 4, 1],\n",
       "       [6, 4, 3, 4, 4, 4, 4, 0],\n",
       "       [5, 2, 3, 2, 3, 6, 4, 1],\n",
       "       [4, 2, 3, 2, 3, 6, 3, 1],\n",
       "       [3, 2, 2, 2, 5, 8, 3, 1],\n",
       "       [6, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [5, 2, 2, 2, 3, 6, 4, 1],\n",
       "       [3, 2, 3, 2, 5, 2, 4, 1],\n",
       "       [7, 2, 2, 2, 4, 4, 3, 0],\n",
       "       [7, 2, 2, 2, 4, 4, 3, 1],\n",
       "       [3, 2, 3, 2, 5, 1, 4, 1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6, 4, 3, 4, 4, 4, 4, 0]),\n",
       " array([6, 4, 3, 4, 4, 4, 4, 1]),\n",
       " array([4, 2, 2, 2, 4, 4, 3, 0]),\n",
       " array([3, 2, 3, 2, 3, 6, 3, 0]),\n",
       " array([5, 2, 3, 2, 3, 6, 4, 1]),\n",
       " array([3, 2, 2, 2, 5, 8, 3, 1])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_paretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 4NORM IS 16RELU IS 6 INT RELU0 WEIGHTS 1 ARE 4 BIASES 1 ARE 3 WEIGHTS 2 ARE 4 BIASES 2 ARE 4 SPARSITY : 0.4\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "[array([[ 0.5  , -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.   ],\n",
      "       [ 0.875, -0.375,  0.   ],\n",
      "       [ 0.75 , -0.625,  0.   ],\n",
      "       [-1.   ,  0.5  ,  0.   ],\n",
      "       [-0.5  ,  0.   ,  0.   ],\n",
      "       [-1.   ,  0.875,  0.   ]], dtype=float32), array([ 0.75,  0.75, -0.25], dtype=float32), array([[ 0.875, -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.875],\n",
      "       [ 0.   ,  0.   ,  0.   ]], dtype=float32), array([-0.125,  0.5  , -0.375], dtype=float32)]\n",
      " ACCURACY IS 0.9523809552192688\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 4NORM IS 16RELU IS 6 INT RELU1 WEIGHTS 1 ARE 4 BIASES 1 ARE 3 WEIGHTS 2 ARE 4 BIASES 2 ARE 4 SPARSITY : 0.4\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0068s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "[array([[ 0.5  , -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.   ],\n",
      "       [ 0.875, -0.375,  0.   ],\n",
      "       [ 0.75 , -0.625,  0.   ],\n",
      "       [-1.   ,  0.5  ,  0.   ],\n",
      "       [-0.5  ,  0.   ,  0.   ],\n",
      "       [-1.   ,  0.875,  0.   ]], dtype=float32), array([ 0.75,  0.75, -0.25], dtype=float32), array([[ 0.875, -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.875],\n",
      "       [ 0.   ,  0.   ,  0.   ]], dtype=float32), array([-0.125,  0.5  , -0.375], dtype=float32)]\n",
      " ACCURACY IS 0.9523809552192688\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 3NORM IS 8RELU IS 4 INT RELU0 WEIGHTS 1 ARE 2 BIASES 1 ARE 2 WEIGHTS 2 ARE 2 BIASES 2 ARE 4 SPARSITY : 0.4\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0056s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8583 - accuracy: 0.9206\n",
      "[array([[ 0.5,  0. ,  0. ],\n",
      "       [-1. , -1. ,  0. ],\n",
      "       [ 0.5,  0. ,  0. ],\n",
      "       [ 0.5, -0.5,  0. ],\n",
      "       [-0.5,  0. ,  0. ],\n",
      "       [ 0. ,  0.5,  0. ],\n",
      "       [-1. ,  0.5,  0. ]], dtype=float32), array([ 0.5,  0.5, -0.5], dtype=float32), array([[ 0.5, -1. ,  0. ],\n",
      "       [-1. , -1. ,  0.5],\n",
      "       [ 0. ,  0. ,  0. ]], dtype=float32), array([ 0.125,  0.375, -0.375], dtype=float32)]\n",
      " ACCURACY IS 0.920634925365448\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 3NORM IS 8RELU IS 3 INT RELU0 WEIGHTS 1 ARE 2 BIASES 1 ARE 3 WEIGHTS 2 ARE 2 BIASES 2 ARE 3 SPARSITY : 0.6\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0050s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9103 - accuracy: 0.8730\n",
      "[array([[ 0. , -1. ,  0. ],\n",
      "       [-1. ,  0. ,  0. ],\n",
      "       [ 0.5,  0. ,  0. ],\n",
      "       [ 0.5,  0. ,  0. ],\n",
      "       [-1. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0.5,  0. ]], dtype=float32), array([ 0.75,  0.75, -0.25], dtype=float32), array([[ 0. , -1. ,  0.5],\n",
      "       [-1. , -1. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. ]], dtype=float32), array([ 0.25,  0.75, -0.75], dtype=float32)]\n",
      " ACCURACY IS 0.8730158805847168\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 4NORM IS 16RELU IS 5 INT RELU1 WEIGHTS 1 ARE 2 BIASES 1 ARE 3 WEIGHTS 2 ARE 2 BIASES 2 ARE 3 SPARSITY : 0.6\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "[array([[ 0. , -1. ,  0. ],\n",
      "       [-1. ,  0. ,  0. ],\n",
      "       [ 0.5,  0. ,  0. ],\n",
      "       [ 0.5,  0. ,  0. ],\n",
      "       [-1. ,  0. ,  0. ],\n",
      "       [ 0. ,  0. ,  0. ],\n",
      "       [ 0. ,  0.5,  0. ]], dtype=float32), array([ 0.75,  0.75, -0.25], dtype=float32), array([[ 0. , -1. ,  0.5],\n",
      "       [ 0. , -1. ,  0.5],\n",
      "       [ 0. ,  0. ,  0. ]], dtype=float32), array([ 0.  ,  0.75, -0.75], dtype=float32)]\n",
      " ACCURACY IS 0.7460317611694336\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 3NORM IS 8RELU IS 3 INT RELU1 WEIGHTS 1 ARE 2 BIASES 1 ARE 2 WEIGHTS 2 ARE 2 BIASES 2 ARE 5 SPARSITY : 0.8\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0075s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1202 - accuracy: 0.6190\n",
      "[array([[0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. ],\n",
      "       [0.5, 0. , 0. ],\n",
      "       [0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. ],\n",
      "       [0. , 0.5, 0. ]], dtype=float32), array([ 0.5,  0.5, -0.5], dtype=float32), array([[ 0. ,  0. ,  0. ],\n",
      "       [-0.5,  0. ,  0.5],\n",
      "       [ 0. ,  0. ,  0. ]], dtype=float32), array([ 0.4375,  0.1875, -0.4375], dtype=float32)]\n",
      " ACCURACY IS 0.6190476417541504\n"
     ]
    }
   ],
   "source": [
    "import weightsharing as ws\n",
    "from importlib import reload\n",
    "\n",
    "weights_all=[]\n",
    "accuracy_all=[]\n",
    "for sol in true_paretos:\n",
    "\n",
    "    sparsity_val = float(sol[5]/10)\n",
    "    relusize_f = int(sol[0])\n",
    "    weight_size_f1 = int(sol[1])\n",
    "    bias_size_f1 = int(sol[2])\n",
    "    weight_size_f2 = int(sol[3])\n",
    "    bias_size_f2 = int(sol[4])\n",
    "    input_s = int(sol[6])\n",
    "    int_relu = int(sol[7])\n",
    "    int_w1=0\n",
    "    int_b1=0\n",
    "    int_w2=0\n",
    "    int_b2=0\n",
    "    input_size = int(input_s)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    layer1=7\n",
    "    layer2=3\n",
    "    layer3=3\n",
    "    i=99\n",
    "    epochs=14\n",
    "    lr=0.003\n",
    "    X = df.drop('Y', axis = 1).values\n",
    "    y = df.Y\n",
    "    le = LabelEncoder()\n",
    "    print(y)\n",
    "    y = le.fit_transform(y)\n",
    "    print(le.classes_)\n",
    "    y = to_categorical(y, 3)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "    print(X_train.shape)\n",
    "    # reload(pv)\n",
    "    # model=pv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,sparsity,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "    norm = 2**input_s\n",
    "    sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i] = [int(x*norm)/norm for x in X_train[i]]\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i] = [int(x*norm)/norm for x in X_test[i]]\n",
    "\n",
    "\n",
    "    print(\"INPUT IS \" + str(input_s)+ \"NORM IS \" + str(norm)+ \"RELU IS \"+str(relusize_f)+\" INT RELU\" +str(int_relu)+\" WEIGHTS 1 ARE \"+str(weight_size_f1)+\" BIASES 1 ARE \"+str(bias_size_f1)+\" WEIGHTS 2 ARE \"+str(weight_size_f2)+\" BIASES 2 ARE \"+str(bias_size_f2)+\" SPARSITY : \"+str(sparsity_val))\n",
    "\n",
    "    weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "    relu_size=(relusize_f,int_relu)\n",
    "\n",
    "    model.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "    model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "    model.add(QDense(layer3, name='output',\n",
    "                    kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                    kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "    pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=300, frequency=100)}\n",
    "    model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    model.layers[0].set_weights(wb1)\n",
    "    model.layers[2].set_weights(wb2)\n",
    "\n",
    "    adam = Adam(lr=0.003)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks= all_callbacks( outputDir = 'seeds_classification_prune')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(X_train, Y_train, batch_size=1,\n",
    "                epochs=14,validation_split=0.2, verbose=0, shuffle=True,\n",
    "                callbacks = callbacks.callbacks);\n",
    "    model = strip_pruning(model)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "    accuracy=model.evaluate(X_test,Y_test)\n",
    "    print(model.get_weights())\n",
    "    print(\" ACCURACY IS \"+str(accuracy[1]) )\n",
    "    accuracy_all.append(accuracy[1])\n",
    "    weights_all.append(model.trainable_variables)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "205    3\n",
      "206    3\n",
      "207    3\n",
      "208    3\n",
      "209    3\n",
      "Name: Y, Length: 210, dtype: int64\n",
      "[1 2 3]\n",
      "(147, 7)\n",
      "INPUT IS 4NORM IS 16RELU IS 6 INT RELU0 WEIGHTS 1 ARE 4 BIASES 1 ARE 3 WEIGHTS 2 ARE 4 BIASES 2 ARE 4 SPARSITY : 0.4\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0058s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "[array([[ 0.5  , -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.   ],\n",
      "       [ 0.875, -0.375,  0.   ],\n",
      "       [ 0.75 , -0.625,  0.   ],\n",
      "       [-1.   ,  0.5  ,  0.   ],\n",
      "       [-0.5  ,  0.   ,  0.   ],\n",
      "       [-1.   ,  0.875,  0.   ]], dtype=float32), array([ 0.75,  0.75, -0.25], dtype=float32), array([[ 0.875, -1.   ,  0.   ],\n",
      "       [-1.   , -1.   ,  0.875],\n",
      "       [ 0.   ,  0.   ,  0.   ]], dtype=float32), array([-0.125,  0.5  , -0.375], dtype=float32)]\n",
      " ACCURACY IS 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "import weightsharing as ws\n",
    "from importlib import reload\n",
    "import copy\n",
    "\n",
    "#weights_all=[]\n",
    "#accuracy_all=[]\n",
    "sol=copy.deepcopy(true_paretos[0])\n",
    "\n",
    "sparsity_val = float(sol[5]/10)\n",
    "relusize_f = int(sol[0])\n",
    "weight_size_f1 = int(sol[1])\n",
    "bias_size_f1 = int(sol[2])\n",
    "weight_size_f2 = int(sol[3])\n",
    "bias_size_f2 = int(sol[4])\n",
    "input_s = int(sol[6])\n",
    "int_relu = int(sol[7])\n",
    "int_w1=0\n",
    "int_b1=0\n",
    "int_w2=0\n",
    "int_b2=0\n",
    "input_size = int(input_s)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "layer1=7\n",
    "layer2=3\n",
    "layer3=3\n",
    "i=99\n",
    "epochs=14\n",
    "lr=0.003\n",
    "X = df.drop('Y', axis = 1).values\n",
    "y = df.Y\n",
    "le = LabelEncoder()\n",
    "print(y)\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 3)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "print(X_train.shape)\n",
    "# reload(pv)\n",
    "# model=pv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,sparsity,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "norm = 2**input_s\n",
    "sc = MinMaxScaler(feature_range=(0,0.9))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "for i in range(0,len(X_train)):\n",
    "    X_train[i] = [int(x*norm)/norm for x in X_train[i]]\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test[i] = [int(x*norm)/norm for x in X_test[i]]\n",
    "\n",
    "\n",
    "print(\"INPUT IS \" + str(input_s)+ \"NORM IS \" + str(norm)+ \"RELU IS \"+str(relusize_f)+\" INT RELU\" +str(int_relu)+\" WEIGHTS 1 ARE \"+str(weight_size_f1)+\" BIASES 1 ARE \"+str(bias_size_f1)+\" WEIGHTS 2 ARE \"+str(weight_size_f2)+\" BIASES 2 ARE \"+str(bias_size_f2)+\" SPARSITY : \"+str(sparsity_val))\n",
    "\n",
    "weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "relu_size=(relusize_f,int_relu)\n",
    "\n",
    "model.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(layer3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=300, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "model.layers[0].set_weights(wb1)\n",
    "model.layers[2].set_weights(wb2)\n",
    "\n",
    "adam = Adam(lr=0.003)\n",
    "\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "callbacks= all_callbacks( outputDir = 'seeds_classification_prune')\n",
    "callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "model.fit(X_train, Y_train, batch_size=1,\n",
    "            epochs=14,validation_split=0.2, verbose=0, shuffle=True,\n",
    "            callbacks = callbacks.callbacks);\n",
    "model = strip_pruning(model)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "print(model.get_weights())\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )\n",
    "accuracy_all.append(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      " ACCURACY IS 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "model.set_weights(weights_all[0])\n",
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )\n",
    "accuracy_all.append(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      " ACCURACY IS 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "model5=Sequential()\n",
    "model5.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model5.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model5.add(QDense(layer3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model5.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model5.set_weights(weights_all[0])\n",
    "\n",
    "model5.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "\n",
    "accuracy=model5.evaluate(X_test,Y_test)\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for solution in paretos:\n",
    "    relusize_f=solution[0]\n",
    "    weight_size_f1=solution[1]\n",
    "    bias_size_f1=solution[2]\n",
    "    weight_size_f2=solution[3]\n",
    "    bias_size_f2=solution[4]\n",
    "    sparsity=solution[5]\n",
    "    inputsize=solution[6]\n",
    "    relusize_int=solution[7]\n",
    "    model=pv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,sparsity,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "    #pwsv.generate(model,i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,inputsize,relusize_int,layer1,layer2,layer3,X_train,Y_train,X_test,Y_test)\n",
    "    #pcv.generate(model,i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,inputsize,relusize_int,layer1,layer2,layer3,X_train,Y_train,X_test,Y_test)\n",
    "    #poqv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relusize 8 weight size 1 7 bias size 1 7 weight size 2 7 bias size 2 7 input size 4 reluint 1 sparsity 0.0\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.9206\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_422\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                47        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                23        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 40\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 1s 3ms/step - loss: 0.7370 - accuracy: 0.6923 - val_loss: 0.7880 - val_accuracy: 0.6333\n",
      "... quantizing model\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.7579 - accuracy: 0.6508\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_424\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                48        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                24        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 42\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.8718 - val_loss: 0.5682 - val_accuracy: 0.9000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8413\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_426\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                49        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                25        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 44\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.5746 - accuracy: 0.9402 - val_loss: 0.5604 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.9048\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_428\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                50        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                26        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 46\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.5659 - accuracy: 0.9316 - val_loss: 0.5528 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.9206\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_430\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                51        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                27        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 48\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.5703 - accuracy: 0.9487 - val_loss: 0.5673 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.8889\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_432\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                52        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                28        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 50\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.5746 - accuracy: 0.9402 - val_loss: 0.5604 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.9048\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_434\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                53        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                29        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82\n",
      "Trainable params: 52\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.5869 - accuracy: 0.9487 - val_loss: 0.5711 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.8889\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "Model: \"sequential_436\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_fc1 (ClusterWeights  (None, 3)                54        \n",
      " )                                                               \n",
      "                                                                 \n",
      " cluster_relu1 (ClusterWeigh  (None, 3)                0         \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_output (ClusterWeig  (None, 3)                30        \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_softmax (ClusterWei  (None, 3)                0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 54\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.9487 - val_loss: 0.5777 - val_accuracy: 1.0000\n",
      "... quantizing model\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.8889\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    }
   ],
   "source": [
    "reload(pcv)\n",
    "i=0\n",
    "relusize_f=8#solution[0]\n",
    "weight_size_f1=7#solution[1]\n",
    "bias_size_f1=7#solution[2]\n",
    "weight_size_f2=7#solution[3]\n",
    "bias_size_f2=7#solution[4]\n",
    "sparsity=0#solution[5]\n",
    "inputsize=4#solution[6]\n",
    "relusize_int=1#solution[7]\n",
    "model=pv.generate(i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,sparsity,inputsize,relusize_int,layer1,layer2,layer3,lr,epochs,X_train,Y_train,X_test,Y_test,wb1,wb2)\n",
    "#pwsv.generate(model,i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,inputsize,relusize_int,layer1,layer2,layer3,X_train,Y_train,X_test,Y_test)\n",
    "pcv.generate(model,i,relusize_f,weight_size_f1,bias_size_f1,weight_size_f2,bias_size_f2,inputsize,relusize_int,layer1,layer2,layer3,X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 4ms/step - loss: 0.6911 - accuracy: 0.7302\n",
      "accuracy = 0.7301587462425232\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.7302\n",
      "accuracy = 0.7301587462425232\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.7302\n",
      "accuracy = 0.7301587462425232\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 4ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/Desktop/TC/genetic_seeds/sharing.py:173: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6025 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    }
   ],
   "source": [
    "import sharing as sh\n",
    "reload(sh)\n",
    "bits_l1=7\n",
    "bits_int_l1=1\n",
    "bits_l2=7\n",
    "bits_int_l2=1\n",
    "\n",
    "\n",
    "bias_l1=7\n",
    "bias_l2=7\n",
    "bias_int_l1=1\n",
    "bias_int_l2=1\n",
    "relu_int=2\n",
    "relu=8\n",
    "layer1 = 7\n",
    "layer2 = 3\n",
    "layer3 = 3\n",
    "\n",
    "window=8\n",
    "for i in range(1,layer2+1):\n",
    "    for j in range(1,layer3+1):\n",
    "        c1 = i\n",
    "        c2 = j\n",
    "        sh.top_sharing(weights1, bits_l1, bits_int_l1, bits_l2, bits_int_l2, bias_l1, bias_int_l1, bias_l2, bias_int_l2, 4, relu, relu_int, X_test, Y_test, layer1, layer2, layer3, c1, c2, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       " array([[ 0.5  , -1.   ,  0.   ],\n",
       "        [-1.   , -1.   ,  0.   ],\n",
       "        [ 0.875, -0.375,  0.   ],\n",
       "        [ 0.75 , -0.625,  0.   ],\n",
       "        [-1.   ,  0.5  ,  0.   ],\n",
       "        [-0.5  ,  0.   ,  0.   ],\n",
       "        [-1.   ,  0.875,  0.   ]], dtype=float32)>,\n",
       " <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       " <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 0.875, -1.   ,  0.   ],\n",
       "        [-1.   , -1.   ,  0.875],\n",
       "        [ 0.   ,  0.   ,  0.   ]], dtype=float32)>,\n",
       " <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([-0.125,  0.5  , -0.375], dtype=float32)>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"paretos_seeds\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(true_paretos, fp)\n",
    "# with open(\"weights_list_true_paretos_seeds\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(weights_all, fp)\n",
    "# with open(\"accuracies_true_paretos_seeds\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(accuracy_all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paretos_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    true_paretos = pickle.load(fp)\n",
    "with open(\"weights_list_true_paretos_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    weights_all = pickle.load(fp)\n",
    "with open(\"accuracies_true_paretos_seeds\", \"rb\") as fp:   # Unpickling\n",
    "    accuracy_all = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "relu = int(true_paretos[0][0])\n",
    "bits_l1 = int(true_paretos[0][1])\n",
    "bias_l1 = int(true_paretos[0][2])\n",
    "bits_l2 = int(true_paretos[0][3])\n",
    "bias_l2 = int(true_paretos[0][4])\n",
    "input_s = int(true_paretos[0][6])\n",
    "relu_int = int(true_paretos[0][7])+1\n",
    "bias_int_l1=1\n",
    "bias_int_l2=1\n",
    "bits_int_l1=1\n",
    "bits_int_l2=1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(bits_l1,bits_int_l1-1,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(bias_l1,bias_int_l1-1,0,alpha=1),kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model1.add(QActivation(activation=quantized_relu(relu,relu_int-1,use_stochastic_rounding=False), name='relu1'))\n",
    "model1.add(QDense(layer3, name='output',\n",
    "          kernel_quantizer=quantized_bits(bits_l2,bits_int_l2-1,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bias_l2,bias_int_l2-1,alpha=1),\n",
    "          kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model1.add(Activation(activation='softmax', name='softmax'))\n",
    "model1.set_weights(weights_all[0])\n",
    "\n",
    "adam = Adam(lr=0.00001)\n",
    "    #callbacks= all_callbacks( outputDir = 'callbacks')\n",
    "model1.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "new_accuracy=model1.evaluate(X_test,Y_test)\n",
    "print(\"accuracy = \"+str(new_accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT IS 4NORM IS 8RELU IS 6 INT RELU0 WEIGHTS 1 ARE 4 BIASES 1 ARE 3 WEIGHTS 2 ARE 4 BIASES 2 ARE 4 SPARSITY : 0.8\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.7514 - accuracy: 0.8889\n",
      "accuracy = 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "sparsity_val = float(sol[5]/10)\n",
    "relusize_f = int(sol[0])\n",
    "weight_size_f1 = int(sol[1])\n",
    "bias_size_f1 = int(sol[2])\n",
    "weight_size_f2 = int(sol[3])\n",
    "bias_size_f2 = int(sol[4])\n",
    "input_s = int(sol[6])\n",
    "int_relu = int(sol[7])\n",
    "int_w1=0\n",
    "int_b1=0\n",
    "int_w2=0\n",
    "int_b2=0\n",
    "input_size = int(input_s)\n",
    "\n",
    "relusize_f = int(true_paretos[0][0])\n",
    "weight_size_f1 = int(true_paretos[0][1])\n",
    "bias_size_f1 = int(true_paretos[0][2])\n",
    "weight_size_f2 = int(true_paretos[0][3])\n",
    "bias_size_f2 = int(true_paretos[0][4])\n",
    "input_s = int(true_paretos[0][6])\n",
    "int_relu = int(true_paretos[0][7])\n",
    "int_w1=0\n",
    "int_b1=0\n",
    "int_w2=0\n",
    "int_b2=0\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "layer1=7\n",
    "layer2=3\n",
    "layer3=3\n",
    "\n",
    "\n",
    "print(\"INPUT IS \" + str(input_s)+ \"NORM IS \" + str(norm)+ \"RELU IS \"+str(relusize_f)+\" INT RELU\" +str(int_relu)+\" WEIGHTS 1 ARE \"+str(weight_size_f1)+\" BIASES 1 ARE \"+str(bias_size_f1)+\" WEIGHTS 2 ARE \"+str(weight_size_f2)+\" BIASES 2 ARE \"+str(bias_size_f2)+\" SPARSITY : \"+str(sparsity_val))\n",
    "\n",
    "weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "relu_size=(relusize_f,int_relu)\n",
    "\n",
    "model.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(layer3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model.set_weights(weights_all[0])\n",
    "\n",
    "adam = Adam(lr=0.00001)\n",
    "    #callbacks= all_callbacks( outputDir = 'callbacks')\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "new_accuracy=model.evaluate(X_test,Y_test)\n",
    "print(\"accuracy = \"+str(new_accuracy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n",
      "frozen dataset 2\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.7526 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "# create a model with the selected bitwidths and find the zero cost weights (or the duplicates)\n",
    "clusters1=3\n",
    "clusters2=3\n",
    "window=0\n",
    "half_window = 1\n",
    "from sklearn.cluster import KMeans\n",
    "from mult_area import mult_area\n",
    "import copy\n",
    "\n",
    "relu = int(true_paretos[0][0])\n",
    "bits_l1 = int(true_paretos[0][1])\n",
    "bias_l1 = int(true_paretos[0][2])\n",
    "bits_l2 = int(true_paretos[0][3])\n",
    "bias_l2 = int(true_paretos[0][4])\n",
    "input_s = int(true_paretos[0][6])\n",
    "relu_int = int(true_paretos[0][7])+1\n",
    "bias_int_l1=1\n",
    "bias_int_l2=1\n",
    "bits_int_l1=1\n",
    "bits_int_l2=1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(bits_l1,bits_int_l1-1,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(bias_l1,bias_int_l1-1,0,alpha=1),kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model1.add(QActivation(activation=quantized_relu(relu,relu_int-1,use_stochastic_rounding=False), name='relu1'))\n",
    "model1.add(QDense(layer3, name='output',\n",
    "          kernel_quantizer=quantized_bits(bits_l2,bits_int_l2-1,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(bias_l2,bias_int_l2-1,alpha=1),\n",
    "          kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model1.add(Activation(activation='softmax', name='softmax'))\n",
    "model1.set_weights(weights_all[0])\n",
    "\n",
    "# for the two layers\n",
    "for node in range(0,1):\n",
    "    GoldenList1=[]\n",
    "    GoldenList2=[]\n",
    "    for i in range(0,bits_l1):\n",
    "        GoldenList1.append( 2**i/(2**(bits_l1-bits_int_l1) ))\n",
    "        GoldenList1.append(- 2**i/(2**(bits_l1-bits_int_l1) ))\n",
    "    for i in range(0,bits_l2):\n",
    "        GoldenList2.append(2**i/(2**(bits_l2-bits_int_l2) ))\n",
    "        GoldenList2.append(-2**i/(2**(bits_l2-bits_int_l2) ))\n",
    "    GoldenList1.append(0)\n",
    "    GoldenList2.append(0)\n",
    "\n",
    "    # We will create \"layer1\" datasets for the first set of weights and \"layer2\" datasets for the second set\n",
    "    # Each one of the first set datasets will contain \"layer2\" weights and each one of the second set of datasets will contain \"layer3\" weights\n",
    "    for ii in range(0,2):\n",
    "\n",
    "        target_layer = ii\n",
    "\n",
    "        # make an intialization depending if we aim the first or the second sets\n",
    "        if target_layer==0:\n",
    "            GoldenList=GoldenList1\n",
    "            inputs=layer1\n",
    "            tvars=model1.trainable_variables[0]\n",
    "            bits=bits_l1\n",
    "            bits_int=bits_int_l1\n",
    "            i_bits=input_s\n",
    "            desired_clusters= clusters1\n",
    "        else:\n",
    "            GoldenList=GoldenList2\n",
    "            inputs=layer2\n",
    "            tvars=model1.trainable_variables[2]\n",
    "            bits=bits_l2\n",
    "            target_layer=2\n",
    "            bits_int=bits_int_l2\n",
    "            i_bits=relu\n",
    "            desired_clusters= clusters2\n",
    "\n",
    "        # extract the datasets in a list format\n",
    "        l=[]\n",
    "        datasets=[]\n",
    "        for i in range(0,inputs):\n",
    "            l.append(tf.get_static_value(tvars[i]))\n",
    "\n",
    "        for i in range(0,inputs):\n",
    "            ls=[]\n",
    "            for i in l[i]:\n",
    "                ls.append(float(i))\n",
    "            datasets.append(ls)\n",
    "\n",
    "        #create the datasets for the clustering\n",
    "        cluster_datasets=[]\n",
    "        positions=[]\n",
    "        frozen_datasets= [0] * inputs\n",
    "        for i in range(0,inputs):\n",
    "            ls_new=[]\n",
    "            pos=[]\n",
    "            index=0\n",
    "            for j in datasets[i]:\n",
    "                if j not in GoldenList:\n",
    "                    ls_new.append(j)\n",
    "                    pos.append(index)\n",
    "                index = index + 1\n",
    "            if len(ls_new):\n",
    "                cluster_datasets.append(ls_new)\n",
    "                positions.append(pos)\n",
    "            else:\n",
    "                frozen_datasets[i]=1\n",
    "                #place holder\n",
    "                cluster_datasets.append([0])\n",
    "                positions.append([0])\n",
    "\n",
    "        #do clustering\n",
    "        for dataset in cluster_datasets:\n",
    "\n",
    "            #re-define the number of clusters\n",
    "            if desired_clusters > len(dataset):\n",
    "                num_clusters = len(dataset)\n",
    "            else:\n",
    "                num_clusters = desired_clusters\n",
    "            array = np.array(dataset)\n",
    "            kmeans = KMeans(n_clusters=num_clusters,random_state=0, n_init=10).fit(array.reshape(-1,1))\n",
    "            centroids=kmeans.cluster_centers_.reshape(-1).tolist()\n",
    "\n",
    "            # round the centroids up to 6 decimals accuracy\n",
    "            for i in range(0,len(centroids)):\n",
    "                centroids[i]=round(centroids[i],6)\n",
    "                # calculate the estimated area overhead of this centroid\n",
    "                #save the sign\n",
    "                qcentroid = int(centroids[i]*(2 ** (bits-bits_int)))\n",
    "                final_centroid = qcentroid\n",
    "                multarea = mult_area[int(i_bits)][abs(int(qcentroid))]\n",
    "                #print(\"here\")\n",
    "\n",
    "                # now for half window to the right if (< 127) and half window to the left if (> 0 ) evaluate the neighbor points\n",
    "                for w in range(1,half_window+1):\n",
    "                    new_centroid = w + qcentroid\n",
    "                    if new_centroid < 127:\n",
    "                        new_multarea = mult_area[int(i_bits)][abs(int(new_centroid))]\n",
    "                        if new_multarea < multarea:\n",
    "                            multarea = new_multarea\n",
    "                            final_centroid = new_centroid\n",
    "\n",
    "                for w in range(1,half_window+1):\n",
    "                    new_centroid = qcentroid - w\n",
    "                    if new_centroid > 0:\n",
    "                        new_multarea = mult_area[int(i_bits)][abs(int(new_centroid))]\n",
    "                        if new_multarea < multarea:\n",
    "                            multarea = new_multarea\n",
    "                            final_centroid = new_centroid\n",
    "                fixed_point_centroid = final_centroid/(2 ** (bits-bits_int))\n",
    "                #print(\"FOUND ANOTHER CENTROID\"+str(final_centroid)+\" AKA \"+str(fixed_point_centroid)+\" INSTEAD OF \"+str(qcentroid)+\" AKA \"+str(centroids[i]))\n",
    "                centroids[i] = fixed_point_centroid\n",
    "            labels=kmeans.labels_.tolist()\n",
    "            index = 0\n",
    "            for i in range(0,len(dataset)):\n",
    "                dataset[i] = centroids[labels[i]]\n",
    "                dataset[i] = int(dataset[i]*(2 ** (bits-bits_int)))\n",
    "                dataset[i] = dataset[i]/(2 ** (bits-bits_int))\n",
    "\n",
    "\n",
    "            #restore weights\n",
    "            restored_weights= copy.deepcopy(datasets)\n",
    "            for i in range(0,inputs):\n",
    "                if frozen_datasets[i]==1:\n",
    "                    print(\"frozen dataset \"+str(i))\n",
    "                else:\n",
    "                    index = 0\n",
    "                    for j in positions[i]:\n",
    "                        restored_weights[i][j] = cluster_datasets[i][index]\n",
    "                        index = index + 1\n",
    "\n",
    "        model1.trainable_variables[target_layer].assign(restored_weights)\n",
    "        adam = Adam(lr=0.00001)\n",
    "            #callbacks= all_callbacks( outputDir = 'callbacks')\n",
    "model1.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "new_accuracy=model1.evaluate(X_test,Y_test)\n",
    "print(\"accuracy = \"+str(new_accuracy[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       " array([[ 0.5  , -1.   ,  0.   ],\n",
       "        [-1.   , -1.   ,  0.   ],\n",
       "        [ 0.875, -0.375,  0.   ],\n",
       "        [ 0.75 , -0.625,  0.   ],\n",
       "        [-1.   ,  0.5  ,  0.   ],\n",
       "        [-0.5  ,  0.   ,  0.   ],\n",
       "        [-1.   ,  0.875,  0.   ]], dtype=float32)>,\n",
       " <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       " <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 0.875, -1.   ,  0.   ],\n",
       "        [-1.   , -1.   ,  0.875],\n",
       "        [ 0.   ,  0.   ,  0.   ]], dtype=float32)>,\n",
       " <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([-0.125,  0.5  , -0.375], dtype=float32)>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0.5  , -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.   ],\n",
       "         [ 0.875, -0.375,  0.   ],\n",
       "         [ 0.75 , -0.625,  0.   ],\n",
       "         [-1.   ,  0.5  ,  0.   ],\n",
       "         [-0.5  ,  0.   ,  0.   ],\n",
       "         [-1.   ,  0.875,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0.875, -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.875],\n",
       "         [ 0.   ,  0.   ,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([-0.125,  0.5  , -0.375], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0.5  , -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.   ],\n",
       "         [ 0.875, -0.375,  0.   ],\n",
       "         [ 0.75 , -0.625,  0.   ],\n",
       "         [-1.   ,  0.5  ,  0.   ],\n",
       "         [-0.5  ,  0.   ,  0.   ],\n",
       "         [-1.   ,  0.875,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0.875, -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.875],\n",
       "         [ 0.   ,  0.   ,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([-0.125,  0.5  , -0.375], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0.5,  0. ,  0. ],\n",
       "         [-1. , -1. ,  0. ],\n",
       "         [ 0.5,  0. ,  0. ],\n",
       "         [ 0.5, -0.5,  0. ],\n",
       "         [-0.5,  0. ,  0. ],\n",
       "         [ 0. ,  0.5,  0. ],\n",
       "         [-1. ,  0.5,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.5,  0.5, -0.5], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0.5, -1. ,  0. ],\n",
       "         [-1. , -1. ,  0.5],\n",
       "         [ 0. ,  0. ,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.125,  0.375, -0.375], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0. , -1. ,  0. ],\n",
       "         [-1. ,  0. ,  0. ],\n",
       "         [ 0.5,  0. ,  0. ],\n",
       "         [ 0.5,  0. ,  0. ],\n",
       "         [-1. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0.5,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0. , -1. ,  0.5],\n",
       "         [-1. , -1. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.25,  0.75, -0.75], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0. , -1. ,  0. ],\n",
       "         [-1. ,  0. ,  0. ],\n",
       "         [ 0.5,  0. ,  0. ],\n",
       "         [ 0.5,  0. ,  0. ],\n",
       "         [-1. ,  0. ,  0. ],\n",
       "         [ 0. ,  0. ,  0. ],\n",
       "         [ 0. ,  0.5,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0. , -1. ,  0.5],\n",
       "         [ 0. , -1. ,  0.5],\n",
       "         [ 0. ,  0. ,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.  ,  0.75, -0.75], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[0.5, 0. , 0. ],\n",
       "         [0. , 0. , 0. ],\n",
       "         [0.5, 0. , 0. ],\n",
       "         [0.5, 0. , 0. ],\n",
       "         [0. , 0. , 0. ],\n",
       "         [0. , 0. , 0. ],\n",
       "         [0. , 0.5, 0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.5,  0.5, -0.5], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0. ,  0. ,  0. ],\n",
       "         [-0.5,  0. ,  0.5],\n",
       "         [ 0. ,  0. ,  0. ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.4375,  0.1875, -0.4375], dtype=float32)>],\n",
       " [<tf.Variable 'fc1/kernel:0' shape=(7, 3) dtype=float32, numpy=\n",
       "  array([[ 0.5  , -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.   ],\n",
       "         [ 0.875, -0.375,  0.   ],\n",
       "         [ 0.75 , -0.625,  0.   ],\n",
       "         [-1.   ,  0.5  ,  0.   ],\n",
       "         [-0.5  ,  0.   ,  0.   ],\n",
       "         [-1.   ,  0.875,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'fc1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.75,  0.75, -0.25], dtype=float32)>,\n",
       "  <tf.Variable 'output/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "  array([[ 0.875, -1.   ,  0.   ],\n",
       "         [-1.   , -1.   ,  0.875],\n",
       "         [ 0.   ,  0.   ,  0.   ]], dtype=float32)>,\n",
       "  <tf.Variable 'output/bias:0' shape=(3,) dtype=float32, numpy=array([-0.125,  0.5  , -0.375], dtype=float32)>]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pareto_sharing as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0075 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7551 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7543 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.4286\n",
      "accuracy = 0.4285714328289032\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7552 - accuracy: 0.9524\n",
      "accuracy = 0.9523809552192688\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.9048\n",
      "accuracy = 0.9047619104385376\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.8413\n",
      "accuracy = 0.841269850730896\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8988 - accuracy: 0.7460\n",
      "accuracy = 0.7460317611694336\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer LecunUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n",
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n",
      "frozen dataset 3\n",
      "frozen dataset 4\n",
      "frozen dataset 5\n",
      "frozen dataset 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen dataset 0\n",
      "frozen dataset 1\n",
      "frozen dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1171 - accuracy: 0.5714\n",
      "accuracy = 0.5714285969734192\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \n"
     ]
    }
   ],
   "source": [
    "for w in range(0,len(true_paretos)):\n",
    "    reload(ps)\n",
    "    relu= int(true_paretos[w][0])\n",
    "    bits_l1= int(true_paretos[w][1])\n",
    "    bias_l1= int(true_paretos[w][2])\n",
    "    bits_l2=  int(true_paretos[w][3])\n",
    "    bias_l2=  int(true_paretos[w][4])\n",
    "    input_s= int(true_paretos[w][6])\n",
    "    relu_int = int(true_paretos[w][7]) + 1\n",
    "    bits_int_l1= 1\n",
    "    bias_int_l1= 1\n",
    "    bits_int_l2 = 1\n",
    "    bias_int_l2 = 1\n",
    "    layer1=7\n",
    "    layer2=3\n",
    "    layer3-3\n",
    "\n",
    "    window=0\n",
    "    for i in range(1,layer2+1):\n",
    "        for j in range(1,layer3+1):\n",
    "            c1 = i\n",
    "            c2 = j\n",
    "            ps.top_sharing(w,weights_all[w], bits_l1, bits_int_l1, bits_l2, bits_int_l2, bias_l1, bias_int_l1, bias_l2, bias_int_l2, input_s, relu, relu_int, X_test, Y_test, layer1, layer2, layer3, c1, c2, window)\n",
    "    window=20\n",
    "    for i in range(1,layer2+1):\n",
    "        for j in range(1,layer3+1):\n",
    "            c1 = i\n",
    "            c2 = j\n",
    "            ps.top_sharing(w,weights_all[w], bits_l1, bits_int_l1, bits_l2, bits_int_l2, bias_l1, bias_int_l1, bias_l2, bias_int_l2, input_s, relu, relu_int, X_test, Y_test, layer1, layer2, layer3, c1, c2, window)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([6, 4, 3, 4, 4, 4, 4, 0]),\n",
       " array([6, 4, 3, 4, 4, 4, 4, 1]),\n",
       " array([4, 2, 2, 2, 4, 4, 3, 0]),\n",
       " array([3, 2, 3, 2, 3, 6, 3, 0]),\n",
       " array([5, 2, 3, 2, 3, 6, 4, 1]),\n",
       " array([3, 2, 2, 2, 5, 8, 3, 1])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
