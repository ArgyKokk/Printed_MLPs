{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the redwine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./winequality-red.csv', sep = ';')\n",
    "print (np.shape(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "       ..\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('quality', axis = 1).values\n",
    "y = df.quality\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "5       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1598, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5\n",
      "1       5\n",
      "2       5\n",
      "3       6\n",
      "4       5\n",
      "       ..\n",
      "1594    5\n",
      "1595    6\n",
      "1596    6\n",
      "1597    5\n",
      "1598    6\n",
      "Name: quality, Length: 1599, dtype: int64\n",
      "[3 4 5 6 7 8]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "print(y)\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "y = to_categorical(y, 6)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n",
      " [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n",
      " [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n",
      " [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n",
      " [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.7 ,  0.56,  0.08, ...,  3.24,  0.66,  9.6 ],\n",
       "       [ 7.8 ,  0.5 ,  0.17, ...,  3.39,  0.48,  9.5 ],\n",
       "       [10.7 ,  0.67,  0.22, ...,  3.28,  0.98,  9.9 ],\n",
       "       ...,\n",
       "       [ 6.7 ,  0.46,  0.24, ...,  3.39,  0.6 , 10.6 ],\n",
       "       [10.5 ,  0.51,  0.64, ...,  3.09,  0.66, 11.8 ],\n",
       "       [ 9.9 ,  0.5 ,  0.24, ...,  3.34,  0.52, 10.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 6 5 6 5 5 5 5 6 7 3 5 5 6 7 5 7 8 5 5 6 5 6 6 6 7 6 5 6 5 5 6 5 6 5 7\n",
      " 5 4 6 5 5 7 5 5 6 7 6 5 6 5 5 5 7 6 6 6 5 5 5 5 7 5 6 6 5 6 5 6 5 6 4 6 6\n",
      " 6 5 8 5 6 6 5 6 5 6 6 7 5 6 7 4 7 6 5 5 5 6 5 6 5 6 5 5 5 7 6 7 6 5 6 5 8\n",
      " 5 6 5 6 7 6 6 5 6 6 6 6 6 6 6 7 6 5 5 6 5 5 5 6 5 5 5 5 6 7 6 8 5 5 5 6 6\n",
      " 6 5 6 7 6 5 6 5 5 6 6 6 7 5 7 5 5 5 6 6 5 5 6 5 7 6 7 6 6 5 5 6 4 6 5 7 5\n",
      " 5 4 5 7 6 5 6 6 7 6 5 5 6 5 7 5 6 6 5 7 5 5 5 6 7 7 5 5 6 6 7 6 5 6 6 6 6\n",
      " 6 7 4 5 5 7 5 5 5 5 6 6 5 7 5 6 6 6 5 4 6 7 6 7 5 6 6 5 5 6 5 6 4 5 6 6 5\n",
      " 6 6 5 5 6 7 7 6 5 6 6 5 6 5 6 5 5 5 6 6 6 7 5 5 6 5 7 5 6 4 6 6 8 6 5 5 6\n",
      " 5 7 6 6 5 5 7 6 6 5 6 6 5 7 6 6 6 6 5 6 5 5 6 4 6 6 6 5 5 5 6 6 6 6 4 7 6\n",
      " 6 6 5 6 7 5 5 6 7 5 5 6 5 6 5 6 5 5 6 5 6 6 6 5 6 4 5 4 5 5 6 5 6 6 5 5 5\n",
      " 5 5 6 5 6 6 6 5 5 6 5 5 6 6 6 7 6 5 5 6 6 5 5 6 7 6 5 6 5 7 5 5 7 5 6 7 7\n",
      " 6 6 5 6 6 7 6 5 7 6 6 6 5 5 5 5 5 6 5 5 5 7 6 7 6 4 5 7 5 5 5 6 6 6 6 6 5\n",
      " 6 5 6 5 6 6 7 4 6 5 6 6 7 5 7 5 5 6 5 5 6 5 6 5 5 6 6 4 5 6 5 7 8 6 7 4]\n"
     ]
    }
   ],
   "source": [
    "ls=np.argmax(Y_test,axis=1)+3\n",
    "print(ls)\n",
    "#np.savetxt('output_classes.dat',ls, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.7   0.56  0.08 ...  3.24  0.66  9.6 ]\n",
      " [ 7.8   0.5   0.17 ...  3.39  0.48  9.5 ]\n",
      " [10.7   0.67  0.22 ...  3.28  0.98  9.9 ]\n",
      " ...\n",
      " [ 6.7   0.46  0.24 ...  3.39  0.6  10.6 ]\n",
      " [10.5   0.51  0.64 ...  3.09  0.66 11.8 ]\n",
      " [ 9.9   0.5   0.24 ...  3.34  0.52 10.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (1119, 11)\n",
      "Shape of X_test:  (480, 11)\n",
      "Shape of y_train:  (1119, 6)\n",
      "Shape of y_test (480, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",Y_train.shape)\n",
    "print(\"Shape of y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.80e+00 5.00e-01 1.70e-01 1.60e+00 8.20e-02 2.10e+01 1.02e+02 9.96e-01\n",
      " 3.39e+00 4.80e-01 9.50e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/argykokk/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from joblib import load\n",
    "loaded_model = load('./RedWine.MLP_clf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.7   0.56  0.08 ...  3.24  0.66  9.6 ]\n",
      " [ 7.8   0.5   0.17 ...  3.39  0.48  9.5 ]\n",
      " [10.7   0.67  0.22 ...  3.28  0.98  9.9 ]\n",
      " ...\n",
      " [ 6.7   0.46  0.24 ...  3.39  0.6  10.6 ]\n",
      " [10.5   0.51  0.64 ...  3.09  0.66 11.8 ]\n",
      " [ 9.9   0.5   0.24 ...  3.34  0.52 10.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 6 5 6 5 5 5 5 6 7 3 5 5 6 7 5 7 8 5 5 6 5 6 6 6 7 6 5 6 5 5 6 5 6 5 7\n",
      " 5 4 6 5 5 7 5 5 6 7 6 5 6 5 5 5 7 6 6 6 5 5 5 5 7 5 6 6 5 6 5 6 5 6 4 6 6\n",
      " 6 5 8 5 6 6 5 6 5 6 6 7 5 6 7 4 7 6 5 5 5 6 5 6 5 6 5 5 5 7 6 7 6 5 6 5 8\n",
      " 5 6 5 6 7 6 6 5 6 6 6 6 6 6 6 7 6 5 5 6 5 5 5 6 5 5 5 5 6 7 6 8 5 5 5 6 6\n",
      " 6 5 6 7 6 5 6 5 5 6 6 6 7 5 7 5 5 5 6 6 5 5 6 5 7 6 7 6 6 5 5 6 4 6 5 7 5\n",
      " 5 4 5 7 6 5 6 6 7 6 5 5 6 5 7 5 6 6 5 7 5 5 5 6 7 7 5 5 6 6 7 6 5 6 6 6 6\n",
      " 6 7 4 5 5 7 5 5 5 5 6 6 5 7 5 6 6 6 5 4 6 7 6 7 5 6 6 5 5 6 5 6 4 5 6 6 5\n",
      " 6 6 5 5 6 7 7 6 5 6 6 5 6 5 6 5 5 5 6 6 6 7 5 5 6 5 7 5 6 4 6 6 8 6 5 5 6\n",
      " 5 7 6 6 5 5 7 6 6 5 6 6 5 7 6 6 6 6 5 6 5 5 6 4 6 6 6 5 5 5 6 6 6 6 4 7 6\n",
      " 6 6 5 6 7 5 5 6 7 5 5 6 5 6 5 6 5 5 6 5 6 6 6 5 6 4 5 4 5 5 6 5 6 6 5 5 5\n",
      " 5 5 6 5 6 6 6 5 5 6 5 5 6 6 6 7 6 5 5 6 6 5 5 6 7 6 5 6 5 7 5 5 7 5 6 7 7\n",
      " 6 6 5 6 6 7 6 5 7 6 6 6 5 5 5 5 5 6 5 5 5 7 6 7 6 4 5 7 5 5 5 6 6 6 6 6 5\n",
      " 6 5 6 5 6 6 7 4 6 5 6 6 7 5 7 5 5 6 5 5 6 5 6 5 5 6 6 4 5 6 5 7 8 6 7 4]\n"
     ]
    }
   ],
   "source": [
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=loaded_model.coefs_[0]\n",
    "b1=loaded_model.intercepts_[0]\n",
    "w2=loaded_model.coefs_[1]\n",
    "b2=loaded_model.intercepts_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb1=[]\n",
    "wb1.append(w1)\n",
    "wb1.append(b1)\n",
    "\n",
    "wb2=[]\n",
    "wb2.append(w2)\n",
    "wb2.append(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(beta_1=0.8868131348915925, beta_2=0.6379705684637716,\n",
       "              epsilon=0.42956678369024237, hidden_layer_sizes=2,\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=150,\n",
       "              momentum=0.7701281241915822, solver=&#x27;lbfgs&#x27;,\n",
       "              validation_fraction=0.7861884994650608)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(beta_1=0.8868131348915925, beta_2=0.6379705684637716,\n",
       "              epsilon=0.42956678369024237, hidden_layer_sizes=2,\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=150,\n",
       "              momentum=0.7701281241915822, solver=&#x27;lbfgs&#x27;,\n",
       "              validation_fraction=0.7861884994650608)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(beta_1=0.8868131348915925, beta_2=0.6379705684637716,\n",
       "              epsilon=0.42956678369024237, hidden_layer_sizes=2,\n",
       "              learning_rate='adaptive', max_iter=150,\n",
       "              momentum=0.7701281241915822, solver='lbfgs',\n",
       "              validation_fraction=0.7861884994650608)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genetic algorithm to determine the relu size, weight size, bias size and sparsity\n",
    "x1: relu_size\n",
    "x2: weight_size\n",
    "x3: bias_size\n",
    "x4: sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem: max( blackbox(x1,x2,x3,x4)\n",
    "         min ( x1*x2*x3)\n",
    "       s.t\n",
    "         2 < x1,x2,x3 < 8\n",
    "         x4 belongs to [0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackbox as bb\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "import area as ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self,weightsbiases1,weightsbiases2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train):\n",
    "        self.weightsbiases1=weightsbiases1\n",
    "        self.weightsbiases2=weightsbiases2\n",
    "        self.layer1=layer1\n",
    "        self.layer2=layer2\n",
    "        self.layer3=layer3\n",
    "        self.X_test=X_test\n",
    "        self.X_train=X_train\n",
    "        self.Y_test=Y_test\n",
    "        self.Y_train=Y_train\n",
    "        #x[0]: relu_size\n",
    "        #x[1]: weight size layer1\n",
    "        #x[2]: bias size layer1\n",
    "        #x[3]: weight size layer2\n",
    "        #x[4]: bias size layer2\n",
    "        #x[5]: pruning sparsity\n",
    "        #x[6]: input size\n",
    "        \n",
    "        super().__init__(n_var=7,\n",
    "                         n_obj=2,\n",
    "                         n_ieq_constr=0,\n",
    "                         xl=np.array([3,2,2,2,2,2,2]),\n",
    "                         xu=np.array([8,7,7,7,7,5,4]),\n",
    "                         vtype=int)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        accuracy, weights = bb.blackbox(self.weightsbiases1,self.weightsbiases2, x[0], x[1], x[2], x[3], x[4], x[5], x[6] ,self.layer1, self.layer2, self.layer3, self.X_test, self.Y_test, self.X_train, self.Y_train)\n",
    "        f1 = 1- accuracy\n",
    "        f2 = ar.area(weights,x[6],x[0],x[1],x[3],self.layer1,self.layer2,self.layer3)\n",
    "\n",
    "        out[\"F\"] = [f1, f2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=11\n",
    "layer2=2\n",
    "layer3=6\n",
    "problem = MyProblem(wb1,wb2,layer1,layer2,layer3,X_test,X_train,Y_test,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithm = NSGA2(\n",
    "    pop_size=5,\n",
    "    n_offsprings=5,\n",
    "    sampling=IntegerRandomSampling(),\n",
    "    eliminate_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.termination import get_termination\n",
    "\n",
    "#set the number of generations\n",
    "termination = get_termination(\"n_gen\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "blackbox() missing 1 required positional argument: 'Y_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtermination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43msave_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mX\n\u001b[1;32m     11\u001b[0m F \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mF\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[1;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/algorithm.py:141\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/algorithm.py:161\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(infills\u001b[38;5;241m=\u001b[39minfills)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/evaluator.py:69\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[0;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# evaluate the solutions (if there are any)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(I) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# update the function evaluation counter\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_evals:\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/evaluator.py:90\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[0;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m X \u001b[38;5;241m=\u001b[39m pop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# call the problem to evaluate the solutions\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_as_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# for each of the attributes set it to the problem\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:187\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[0;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     only_single_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray))\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# this is where the actual evaluation takes place\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# copy it to a numpy array (it might be one of jax at this point)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:227\u001b[0m, in \u001b[0;36mProblem.do\u001b[0;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# do the function evaluation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_elementwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_vectorized(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:245\u001b[0m, in \u001b[0;36mProblem._evaluate_elementwise\u001b[0;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise_func(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# execute the runner\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m elems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# for each evaluation call\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m elems:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# for each key stored for this evaluation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:27\u001b[0m, in \u001b[0;36mLoopedElementwiseEvaluation.__call__\u001b[0;34m(self, f, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [f(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[0;32m~/miniconda3/envs/hls4ml-tutorial/lib/python3.8/site-packages/pymoo/core/problem.py:20\u001b[0m, in \u001b[0;36mElementwiseEvaluationFunction.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mMyProblem._evaluate\u001b[0;34m(self, x, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 29\u001b[0m     accuracy, weights \u001b[38;5;241m=\u001b[39m \u001b[43mbb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblackbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweightsbiases1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweightsbiases2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m accuracy\n\u001b[1;32m     31\u001b[0m     f2 \u001b[38;5;241m=\u001b[39m ar\u001b[38;5;241m.\u001b[39marea(weights,x[\u001b[38;5;241m6\u001b[39m],x[\u001b[38;5;241m0\u001b[39m],x[\u001b[38;5;241m1\u001b[39m],x[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3)\n",
      "\u001b[0;31mTypeError\u001b[0m: blackbox() missing 1 required positional argument: 'Y_train'"
     ]
    }
   ],
   "source": [
    "from pymoo.optimize import minimize\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination,\n",
    "               seed=1,\n",
    "               save_history=True,\n",
    "               verbose=True)\n",
    "X = res.X\n",
    "F = res.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy, weights = bb.blackbox(wb1,wb2, 6, 5, 5, 5, 5, 3, 4 ,layer1, layer2, layer3, X_test, Y_test, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ar.area(weights,4,6,5,5,layer1,layer2,layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of all the pareto solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paretos=res.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot all the solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymoo.visualization.scatter import Scatter\n",
    "pop=res.pop\n",
    "vals=pop.get(\"F\")\n",
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(vals, facecolor=\"none\", edgecolor=\"red\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the pareto solutions from the final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Scatter()\n",
    "plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "plot.add(res.F, facecolor=\"none\", edgecolor=\"blue\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define an optimal solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relusize_f=4\n",
    "weight_size_f1=2\n",
    "bias_size_f1=5\n",
    "weight_size_f2=5\n",
    "bias_size_f2=3\n",
    "sparsity=4.16\n",
    "input_s=4\n",
    "norm = 2**input_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relusize_f=6\n",
    "weight_size_f1=5\n",
    "bias_size_f1=2\n",
    "weight_size_f2=3\n",
    "bias_size_f2=4\n",
    "sparsity=3\n",
    "input_s=3\n",
    "norm = 2**input_s\n",
    "relusizeint=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relusize_f=5\n",
    "weight_size_f1=2\n",
    "bias_size_f1=2\n",
    "weight_size_f2=6\n",
    "bias_size_f2=2\n",
    "sparsity=3.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize the input based on the selected bitwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "for i in range(0,len(X_train)):\n",
    "    X_train[i] = [round(x*norm)/norm for x in X_train[i]]\n",
    "\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test[i] = [round(x*norm)/norm for x in X_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=11\n",
    "layer_2=2\n",
    "layer_3=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model with the optimal solution's parameters and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "sparsity_val = float(sparsity / 10)\n",
    "weight_bias_size=[ [ (weight_size_f1,1), (bias_size_f1,1) ], [ (weight_size_f2,1), (bias_size_f2,1) ] ]\n",
    "relu_size=(relusize_f,relusizeint)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(QDense(layer_2, input_shape=(layer_1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model.add(QDense(layer_3, name='output',\n",
    "                kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(sparsity_val, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n",
    "model.layers[0].set_weights(wb1)\n",
    "model.layers[2].set_weights(wb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import model_save_quantized_weights\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "callbacks= all_callbacks( outputDir = 'model_red_wine_classification_prune')\n",
    "callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "model.fit(X_train, Y_train, batch_size=1,\n",
    "        epochs=14,validation_split=0.2, verbose=0, shuffle=True,\n",
    "        callbacks = callbacks.callbacks);\n",
    "model = strip_pruning(model)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "\n",
    "accuracy=model.evaluate(X_test,Y_test)\n",
    "#print(model.get_weights())\n",
    "print(\" ACCURACY IS \"+str(accuracy[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GZ\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "def aptype_to_size(ap):\n",
    "    if \"ap_int\" in ap:\n",
    "        s=ap.split('<')[1].split('>')[0]\n",
    "        i=s\n",
    "    else:\n",
    "        s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "    return (int(s),int(i))\n",
    "\n",
    "#get weights\n",
    "print(model.get_weights())\n",
    "#scale weights\n",
    "allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "#scale=[2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,_ in enumerate(model.get_weights())]\n",
    "#print(scale)\n",
    "print(allweights)\n",
    "#cast weights to integer & transpose\n",
    "allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "print(allweightsT)\n",
    "weight_list=allweightsT[0::2]\n",
    "bias_list=allweightsT[1::2]\n",
    "print(weight_list)\n",
    "print(bias_list)\n",
    "\n",
    "#set params\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "last_layer=\"linear\"\n",
    "input_size = (input_s,0)\n",
    "relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "\n",
    "weight_bias_size= [\n",
    "    [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "    [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "]  \n",
    "sum_relu_size=[\n",
    "    [(16,6),relu_size],\n",
    "    [(16,6),(32,6)]\n",
    "]\n",
    "print(weight_bias_size)\n",
    "print(sum_relu_size)\n",
    "\n",
    "\n",
    "f=open(\"top.v\",\"w\")\n",
    "\n",
    "import write_mlp_mergemult_ps as wv\n",
    "wv.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "f.close()\n",
    "\n",
    "f=open(\"sim.Xtest\",\"w\")\n",
    "np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "f.close()\n",
    "\n",
    "from joblib import dump\n",
    "dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the network's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering as cl\n",
    "from importlib import reload\n",
    "layer1=11\n",
    "layer2=2 \n",
    "layer3=6  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight clustering for the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_layer=0\n",
    "iterations=0\n",
    "new_accuracy=1\n",
    "accuracies=[]\n",
    "weights=[]\n",
    "while(new_accuracy > 0):\n",
    "    reload(cl)\n",
    "    new_weights, new_accuracy = cl.clustering(model,target_layer,layer1,layer2,layer3,X_test,Y_test,X_train,Y_train, weight_bias_size, relu_size);\n",
    "    iterations = iterations + 1\n",
    "    print(\"Accuracy of iteration \"+str(iterations)+\" for the target layer \"+str(target_layer)+\" is: \"+str(new_accuracy))\n",
    "    model.set_weights(new_weights)\n",
    "    accuracies.append(new_accuracy)\n",
    "    weights.append(new_weights)\n",
    "    if new_accuracy < accuracy[1]-0.03:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(accuracies)\n",
    "if max_value >= accuracy[1]-0.03:\n",
    "    print(\"here\")\n",
    "    max_index = accuracies.index(max_value)\n",
    "    model.set_weights(weights[max_index])\n",
    "else:\n",
    "    model.set_weights(w1)\n",
    "previous_weights=model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight clustering for the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_layer=2\n",
    "iterations=0\n",
    "new_accuracy=1\n",
    "accuracies_1=[]\n",
    "weights_1=[]\n",
    "while(new_accuracy > 0):\n",
    "    reload(cl)\n",
    "    new_weights, new_accuracy = cl.clustering(model,target_layer,layer1,layer2,layer3,X_test,Y_test,X_train,Y_train, weight_bias_size, relu_size);\n",
    "    iterations = iterations + 1\n",
    "    print(\"Accuracy of iteration \"+str(iterations)+\" for the target layer \"+str(target_layer)+\" is: \"+str(new_accuracy))\n",
    "    model.set_weights(new_weights)\n",
    "    accuracies_1.append(new_accuracy)\n",
    "    weights_1.append(new_weights)\n",
    "    if new_accuracy < accuracy[1]-0.03:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(accuracies_1)\n",
    "if max_value >= accuracy[1]-0.03:\n",
    "    print(\"here\")\n",
    "    max_index = accuracies_1.index(max_value)\n",
    "    model.set_weights(weights_1[max_index])\n",
    "else:\n",
    "    model.set_weights(previous_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GZ\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "model_save_quantized_weights(model, \"test_weights\")\n",
    "\n",
    "def aptype_to_size(ap):\n",
    "    if \"ap_int\" in ap:\n",
    "        s=ap.split('<')[1].split('>')[0]\n",
    "        i=s\n",
    "    else:\n",
    "        s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "    return (int(s),int(i))\n",
    "\n",
    "#get weights\n",
    "print(model.get_weights())\n",
    "#scale weights\n",
    "allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model.get_weights())]\n",
    "#scale=[2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,_ in enumerate(model.get_weights())]\n",
    "#print(scale)\n",
    "print(allweights)\n",
    "#cast weights to integer & transpose\n",
    "allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "print(allweightsT)\n",
    "weight_list=allweightsT[0::2]\n",
    "bias_list=allweightsT[1::2]\n",
    "print(weight_list)\n",
    "print(bias_list)\n",
    "\n",
    "#set params\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "last_layer=\"linear\"\n",
    "input_size = (4,0)\n",
    "relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "\n",
    "weight_bias_size= [\n",
    "    [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "    [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "]  \n",
    "sum_relu_size=[\n",
    "    [(16,6),relu_size],\n",
    "    [(16,6),(32,6)]\n",
    "]\n",
    "print(weight_bias_size)\n",
    "print(sum_relu_size)\n",
    "\n",
    "\n",
    "f=open(\"top_clustered_custom.v\",\"w\")\n",
    "\n",
    "import write_mlp_mergemult_ps as wv\n",
    "wv.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "f.close()\n",
    "\n",
    "f=open(\"sim.Xtest\",\"w\")\n",
    "np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "f.close()\n",
    "\n",
    "from joblib import dump\n",
    "dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Clustering using tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cl = Sequential()\n",
    "model_cl.add(Dense(layer2, input_shape=(layer1,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_cl.add(Activation(activation='relu', name='relu1'))\n",
    "model_cl.add(Dense(layer3, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_cl.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model_cl.set_weights(w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 50,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model_cl, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y_train = np.argmax(Y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_model.fit(\n",
    "  X_train,\n",
    "  new_Y_train,\n",
    "  batch_size=1,\n",
    "  epochs=1,\n",
    "  validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clustered_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "clustered_model_weights=final_clustered_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clustered_quantized = Sequential()\n",
    "    # Add an input layer \n",
    "\n",
    "#\n",
    "   \n",
    "model_clustered_quantized.add(QDense(layer2, input_shape=(layer1,), name='fc1', kernel_quantizer=quantized_bits(weight_bias_size[0][0][0],0,alpha=1,use_stochastic_rounding=True),bias_quantizer=quantized_bits(weight_bias_size[0][1][0],0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)   ))\n",
    "model_clustered_quantized.add(QActivation(activation=quantized_relu(relu_size[0],relu_size[1],use_stochastic_rounding=False), name='relu1'))\n",
    "model_clustered_quantized.add(QDense(layer3, name='output',\n",
    "                 kernel_quantizer=quantized_bits(weight_bias_size[1][0][0],0,alpha=1,use_stochastic_rounding=True), bias_quantizer=quantized_bits(weight_bias_size[1][1][0],0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001 ) ))\n",
    "model_clustered_quantized.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model_clustered_quantized.set_weights(clustered_model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_quantized_weights(model_clustered_quantized, \"test_weights_tf_cluster\")\n",
    "model_clustered_quantized.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model_clustered_quantized.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GZ\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n",
    "from qkeras.utils import model_save_quantized_weights\n",
    "model_save_quantized_weights(model_clustered_quantized, \"test_weights\")\n",
    "\n",
    "def aptype_to_size(ap):\n",
    "    if \"ap_int\" in ap:\n",
    "        s=ap.split('<')[1].split('>')[0]\n",
    "        i=s\n",
    "    else:\n",
    "        s,i=ap.split('<')[1].split('>')[0].split(',')\n",
    "    return (int(s),int(i))\n",
    "\n",
    "#get weights\n",
    "print(model_clustered_quantized.get_weights())\n",
    "#scale weights\n",
    "allweights=[t*2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,t in enumerate(model_clustered_quantized.get_weights())]\n",
    "#scale=[2**(weight_bias_size[j//2][j%2][0]-weight_bias_size[j//2][j%2][1]) for j,_ in enumerate(model.get_weights())]\n",
    "#print(scale)\n",
    "print(allweights)\n",
    "#cast weights to integer & transpose\n",
    "allweightsT=[wl.T.astype(int).tolist() for wl in allweights]\n",
    "print(allweightsT)\n",
    "weight_list=allweightsT[0::2]\n",
    "bias_list=allweightsT[1::2]\n",
    "print(weight_list)\n",
    "print(bias_list)\n",
    "\n",
    "#set params\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model_clustered_quantized, granularity='name')\n",
    "\n",
    "last_layer=\"linear\"\n",
    "input_size = (4,0)\n",
    "relu_size= aptype_to_size(config['LayerName']['relu1']['Precision']['result'])\n",
    "\n",
    "\n",
    "weight_bias_size= [\n",
    "    [aptype_to_size(config['LayerName']['fc1']['Precision']['weight']),aptype_to_size(config['LayerName']['fc1']['Precision']['bias'])],\n",
    "    [aptype_to_size(config['LayerName']['output']['Precision']['weight']),aptype_to_size(config['LayerName']['output']['Precision']['bias'])]\n",
    "]  \n",
    "sum_relu_size=[\n",
    "    [(16,6),relu_size],\n",
    "    [(16,6),(32,6)]\n",
    "]\n",
    "print(weight_bias_size)\n",
    "print(sum_relu_size)\n",
    "\n",
    "\n",
    "f=open(\"top_clustered_keras.v\",\"w\")\n",
    "\n",
    "import write_mlp_mergemult_ps as wv\n",
    "wv.write_mlp_verilog(f, input_size, bias_list, weight_list, weight_bias_size, sum_relu_size,last_layer)\n",
    "f.close()\n",
    "\n",
    "f=open(\"sim.Xtest\",\"w\")\n",
    "np.savetxt(f,(X_test*2**input_size[0]).astype(int),fmt='%d',delimiter=' ')\n",
    "f.close()\n",
    "\n",
    "from joblib import dump\n",
    "dump(np.argmax(Y_test,axis=1), \"sim.Ytest\")\n",
    "\n",
    "print(\"copy top.v, sim.Xtest, and sim.Ytest to the synopsys project \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
